{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "\n",
    "def mnist_dataset():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))  # 归一化\n",
    "    ])\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        ####################\n",
    "        '''声明模型对应的参数'''\n",
    "        ####################\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(784, 256)\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.layer3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ####################\n",
    "        '''实现模型函数体，返回未归一化的logits'''\n",
    "        ####################\n",
    "        x = x.view(-1, 784)\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "# 定义损失计算\n",
    "def compute_loss(logits, labels):\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "# 定义准确率计算\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    label = torch.argmax(labels, dim=1)\n",
    "    correct = torch.sum(predictions == label).item()\n",
    "    total = labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# 定义单步训练过程\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    model.train()\n",
    "    logits = model(x)\n",
    "    optimizer.zero_grad()\n",
    "    loss = compute_loss(logits, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义测试函数\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            logits = model(X)\n",
    "            test_loss += compute_loss(logits, y).item() * X.size(0)\n",
    "            correct += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= len(data_loader.dataset)\n",
    "    accuracy = correct / len(data_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实际训练与测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : loss 1.8548702682649096 ; accuracy 0.30428333333333335\n",
      "epoch 1 : loss 1.8051024422374864 ; accuracy 0.25035\n",
      "epoch 2 : loss 1.5769686650415262 ; accuracy 0.37895\n",
      "epoch 3 : loss 1.366286783773328 ; accuracy 0.5770333333333333\n",
      "epoch 4 : loss 1.28166658418489 ; accuracy 0.6205333333333334\n",
      "epoch 5 : loss 1.2788800315156579 ; accuracy 0.6307333333333334\n",
      "epoch 6 : loss 1.290646019763189 ; accuracy 0.6416833333333334\n",
      "epoch 7 : loss 1.3042788376756012 ; accuracy 0.6574833333333333\n",
      "epoch 8 : loss 1.3071002357546706 ; accuracy 0.6673833333333333\n",
      "epoch 9 : loss 1.2713769735541505 ; accuracy 0.6734\n",
      "epoch 10 : loss 1.2165665359789506 ; accuracy 0.67795\n",
      "epoch 11 : loss 1.159590957188451 ; accuracy 0.6882666666666667\n",
      "epoch 12 : loss 1.095249577836568 ; accuracy 0.7192\n",
      "epoch 13 : loss 1.0304454223492494 ; accuracy 0.7416\n",
      "epoch 14 : loss 0.9734991618441418 ; accuracy 0.7370166666666667\n",
      "epoch 15 : loss 0.9307171760216355 ; accuracy 0.7363833333333333\n",
      "epoch 16 : loss 0.9097373141319491 ; accuracy 0.7623666666666666\n",
      "epoch 17 : loss 0.9130440969003675 ; accuracy 0.7590833333333333\n",
      "epoch 18 : loss 0.9162666472723398 ; accuracy 0.7375666666666667\n",
      "epoch 19 : loss 0.8894334482890398 ; accuracy 0.7449333333333333\n",
      "epoch 20 : loss 0.8448787545912744 ; accuracy 0.7725333333333333\n",
      "epoch 21 : loss 0.8134866299666464 ; accuracy 0.7857666666666666\n",
      "epoch 22 : loss 0.7998073339852737 ; accuracy 0.7795166666666666\n",
      "epoch 23 : loss 0.7893548083362208 ; accuracy 0.7723666666666666\n",
      "epoch 24 : loss 0.7733928340555944 ; accuracy 0.7734166666666666\n",
      "epoch 25 : loss 0.7550201487199442 ; accuracy 0.7800666666666667\n",
      "epoch 26 : loss 0.7406904998606575 ; accuracy 0.78555\n",
      "epoch 27 : loss 0.731225619978124 ; accuracy 0.7902666666666667\n",
      "epoch 28 : loss 0.7214385270680611 ; accuracy 0.7949833333333334\n",
      "epoch 29 : loss 0.7072369088387971 ; accuracy 0.8018333333333333\n",
      "epoch 30 : loss 0.6901518471061873 ; accuracy 0.81045\n",
      "epoch 31 : loss 0.6739477090302428 ; accuracy 0.8164333333333333\n",
      "epoch 32 : loss 0.660653921806172 ; accuracy 0.8209833333333333\n",
      "epoch 33 : loss 0.6506756314735588 ; accuracy 0.8246\n",
      "epoch 34 : loss 0.6435057393240626 ; accuracy 0.82645\n",
      "epoch 35 : loss 0.6376026069077003 ; accuracy 0.8264333333333334\n",
      "epoch 36 : loss 0.6310003276453412 ; accuracy 0.8283\n",
      "epoch 37 : loss 0.6225612842170619 ; accuracy 0.8306166666666667\n",
      "epoch 38 : loss 0.6125112677510633 ; accuracy 0.8344166666666667\n",
      "epoch 39 : loss 0.6018489546676593 ; accuracy 0.8374833333333334\n",
      "epoch 40 : loss 0.5917312848164836 ; accuracy 0.8397833333333333\n",
      "epoch 41 : loss 0.5831917929883221 ; accuracy 0.8408833333333333\n",
      "epoch 42 : loss 0.576737242892565 ; accuracy 0.8406166666666667\n",
      "epoch 43 : loss 0.5718651758020638 ; accuracy 0.8409333333333333\n",
      "epoch 44 : loss 0.5672645949066966 ; accuracy 0.8414666666666667\n",
      "epoch 45 : loss 0.5617250398465325 ; accuracy 0.8435\n",
      "epoch 46 : loss 0.5548683539572385 ; accuracy 0.8456333333333333\n",
      "epoch 47 : loss 0.5471868654114165 ; accuracy 0.8483666666666667\n",
      "epoch 48 : loss 0.5396655179940416 ; accuracy 0.8513333333333334\n",
      "epoch 49 : loss 0.5332510187061847 ; accuracy 0.8539333333333333\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = mnist_dataset()\n",
    "num_train_samples = len(train_loader.dataset)\n",
    "num_test_samples = len(test_loader.dataset)\n",
    "num_classes = 10  # MNIST数据集有10个类别\n",
    "\n",
    "train_labels = np.zeros((num_train_samples, num_classes))\n",
    "test_labels = np.zeros((num_test_samples, num_classes))\n",
    "\n",
    "train_images = torch.zeros((num_train_samples, 1, 28, 28))\n",
    "test_images = torch.zeros((num_test_samples, 1, 28, 28))\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    one_hot_labels = F.one_hot(labels, num_classes=num_classes)\n",
    "    start_idx = batch_idx * train_loader.batch_size\n",
    "    end_idx = start_idx + labels.size(0)\n",
    "    train_labels[start_idx:end_idx, :] = one_hot_labels.numpy()\n",
    "    train_images[start_idx:end_idx] = images\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "    one_hot_labels = F.one_hot(labels, num_classes=num_classes)\n",
    "    start_idx = batch_idx * test_loader.batch_size\n",
    "    end_idx = start_idx + labels.size(0)\n",
    "    test_labels[start_idx:end_idx, :] = one_hot_labels.numpy()\n",
    "    test_images[start_idx:end_idx] = images\n",
    "\n",
    "# print(train_images.shape, train_labels.shape)\n",
    "# print(test_images.shape, test_labels.shape)\n",
    "\n",
    "train_images = train_images.reshape(60000, 784)\n",
    "test_images = test_images.reshape(10000, 784)\n",
    "\n",
    "# print(train_images.shape, train_labels.shape)\n",
    "# print(test_images.shape, test_labels.shape)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# 每个epoch（整个测试集）训练一次\n",
    "for epoch in range(50):\n",
    "    loss, accuracy =  train_one_step(model, optimizer, train_images, train_labels)\n",
    "    print('epoch', epoch, ': loss', loss.detach().numpy(), '; accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.507794650888443, Test Accuracy: 0.8624\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
